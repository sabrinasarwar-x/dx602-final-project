{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DX 602 Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, you will practice the skills that you have learned throughout this module with a heavy focus on building models.\n",
    "Most of the problems and questions are open ended compared to your previous homeworks, and you will be asked to explain your choices.\n",
    "Most of them will have a particular type of solution implied, but it is up to you to figure out the details based on what you have learned in this module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "Each problem asks you to perform build models, run a computation, or otherwise perform some analysis of the data, and usually answer some questions about the results.\n",
    "Make sure that your question answers are well supported by your analysis and explanations; simply stating an answer without support will earn minimal points.\n",
    "\n",
    "Notebook cells for code and text have been added for your convenience, but feel free to add additional cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example Code\n",
    "\n",
    "You may find it helpful to refer to this GitHub repository of Jupyter notebooks for example code.\n",
    "\n",
    "* https://github.com/bu-cds-omds/dx601-examples\n",
    "* https://github.com/bu-cds-omds/dx602-examples\n",
    "\n",
    "Any calculations demonstrated in code examples or videos may be found in these notebooks, and you are allowed to copy this example code in your homework answers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "This project will be entirely manually graded.\n",
    "However, we may rerun some or all of your code to confirm that it works as described."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Late Policy\n",
    "\n",
    "The normal homework late policy for OMDS does not apply to this project.\n",
    "Boston University requires final grades to be submitted within 72 hours of class instruction ending, so we cannot accommodate 5 days of late submissions.\n",
    "\n",
    "However, we have delayed the due date of this project to be substantially later than necessary given its scope, and given you more days for submission with full credit than you would have had days for submission with partial credit under the homework late policy.\n",
    "The Thanksgiving holiday was also taken into account in setting the deadline.\n",
    "Finally, the deadlines for DX 601 and DX 602 were coordinated to be a week apart while giving ample time for both of their projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shared Imports\n",
    "\n",
    "For this project, you are forbidden to use modules that were not loaded in this template.\n",
    "While other modules are handy in practice, modules that trivialize these problems interfere with our assessment of your own knowledge and skills.\n",
    "\n",
    "If you believe a module covered in the course material (not live sessions) is missing, please check with your learning facilitator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1 (5 points)\n",
    "\n",
    "Pick one of the following data sets to analyze in this project.\n",
    "Load the data set, and show a random sample of 10 rows.\n",
    "\n",
    "* [Wine Quality](https://archive.ics.uci.edu/dataset/186/wine+quality) ([PMLB - red subset only](https://github.com/EpistasisLab/pmlb/tree/master/datasets/wine_quality_red))\n",
    "* [Body Fat](https://www.openml.org/search?type=data&status=active&id=560) ([PMLB](https://github.com/EpistasisLab/pmlb/tree/master/datasets/560_bodyfat))\n",
    "\n",
    "The PMLB copies of the data are generally cleaner and recommended for this project, but the other links are provided to give you more context.\n",
    "To load the data from the PMLB Github repository, navigate to the `.tsv.gz` file in GitHub and copy the link from the \"Raw\" button.\n",
    "\n",
    "If the dataset has missing data, you should drop the rows with missing data before proceeding.\n",
    "If the data set you choose has more than ten columns, you may limit later analysis that is requested per column to just the first ten columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows read (including header): 3\n",
      "Total data rows: 2\n",
      "\n",
      "Columns:\n",
      "['version https://git-lfs.github.com/spec/v1']\n",
      "\n",
      "Random sample of 10 rows:\n",
      "\n",
      "['oid sha256:479f25b491115302fb2adaaa80f2670ab812154007d68ec5c566a45f6210d04d']\n",
      "['size 10551']\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import csv\n",
    "import random\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/datasets/560_bodyfat/560_bodyfat.tsv.gz\"\n",
    "\n",
    "\n",
    "raw_bytes = urllib.request.urlopen(url).read()\n",
    "\n",
    "\n",
    "if raw_bytes[:2] == b\"\\x1f\\x8b\":\n",
    "    text_data = gzip.decompress(raw_bytes).decode(\"utf-8\")\n",
    "else:\n",
    "    text_data = raw_bytes.decode(\"utf-8\")\n",
    "\n",
    "lines = text_data.splitlines()\n",
    "reader = csv.reader(lines, delimiter=\"\\t\")\n",
    "\n",
    "rows = list(reader)\n",
    "\n",
    "# Basic sanity check so we don't sample from nothing\n",
    "print(\"Total rows read (including header):\", len(rows))\n",
    "\n",
    "header = rows[0]\n",
    "data = rows[1:]\n",
    "\n",
    "print(\"Total data rows:\", len(data))\n",
    "print(\"\\nColumns:\")\n",
    "print(header)\n",
    "\n",
    "\n",
    "if len(data) >= 10:\n",
    "    sample = random.sample(data, 10)\n",
    "else:\n",
    "    sample = data  # fallback: print what we have\n",
    "\n",
    "print(\"\\nRandom sample of 10 rows:\\n\")\n",
    "for row in sample:\n",
    "    print(row)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2 (10 points)\n",
    "\n",
    "List all of the columns and describe them in your own words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column Descriptions:\n",
      "\n",
      "version https://git-lfs.github.com/spec/v1: Column description not available.\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import gzip\n",
    "import csv\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/EpistasisLab/pmlb/master/datasets/560_bodyfat/560_bodyfat.tsv.gz\"\n",
    "\n",
    "raw_data = urllib.request.urlopen(url).read()\n",
    "\n",
    "if raw_data[:2] == b\"\\x1f\\x8b\":\n",
    "    text_data = gzip.decompress(raw_data).decode(\"utf-8\")\n",
    "else:\n",
    "    text_data = raw_data.decode(\"utf-8\")\n",
    "\n",
    "lines = text_data.splitlines()\n",
    "reader = csv.reader(lines, delimiter=\"\\t\")\n",
    "rows = list(reader)\n",
    "\n",
    "columns = rows[0]\n",
    "\n",
    "descriptions = {\n",
    "    \"bodyfat\": \"The percentage of body fat in a personâ€™s body.\",\n",
    "    \"density\": \"Overall body density, measured using underwater weighing.\",\n",
    "    \"age\": \"Age of the person in years.\",\n",
    "    \"weight\": \"Body weight measured in pounds.\",\n",
    "    \"height\": \"Height of the person measured in inches.\",\n",
    "    \"neck\": \"Neck circumference in centimeters.\",\n",
    "    \"chest\": \"Chest circumference in centimeters.\",\n",
    "    \"abdomen\": \"Abdomen circumference in centimeters, measured at the belly button.\",\n",
    "    \"hip\": \"Hip circumference in centimeters.\",\n",
    "    \"thigh\": \"Thigh circumference in centimeters.\",\n",
    "    \"knee\": \"Knee circumference in centimeters.\",\n",
    "    \"ankle\": \"Ankle circumference in centimeters.\",\n",
    "    \"biceps\": \"Biceps circumference in centimeters.\",\n",
    "    \"forearm\": \"Forearm circumference in centimeters.\",\n",
    "    \"wrist\": \"Wrist circumference in centimeters.\"\n",
    "}\n",
    "\n",
    "print(\"Column Descriptions:\\n\")\n",
    "\n",
    "for col in columns:\n",
    "    print(f\"{col}: {descriptions.get(col, 'Column description not available.')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 3 (50 points)\n",
    "\n",
    "Perform an exploratory analysis of the data set.\n",
    "After your exploratory analysis, pick 3 individual charts that you the think were particularly interesting.\n",
    "Repeat those charts separately from your original analysis, and after each of those charts, explain what you thought was noteworthy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 4 (5 points)\n",
    "\n",
    "Plot the correlation matrix of the numeric columns in the data set.\n",
    "Which pair of different columns were highlighted as the most correlated?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most correlated pair:\n",
      "N/A and N/A (correlation = -1.00)\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "def pearson(x, y):\n",
    "    n = len(x)\n",
    "    if n == 0:\n",
    "        return 0\n",
    "\n",
    "    mean_x = sum(x) / n\n",
    "    mean_y = sum(y) / n\n",
    "\n",
    "    num = 0\n",
    "    denom_x = 0\n",
    "    denom_y = 0\n",
    "\n",
    "    for i in range(n):\n",
    "        dx = x[i] - mean_x\n",
    "        dy = y[i] - mean_y\n",
    "        num += dx * dy\n",
    "        denom_x += dx * dx\n",
    "        denom_y += dy * dy\n",
    "\n",
    "    if denom_x == 0 or denom_y == 0:\n",
    "        return 0\n",
    "\n",
    "    return num / math.sqrt(denom_x * denom_y)\n",
    "\n",
    "\n",
    "\n",
    "columns = header\n",
    "numeric_data = {col: [] for col in columns}\n",
    "\n",
    "for row in data:\n",
    "    for i, col in enumerate(columns):\n",
    "        try:\n",
    "            numeric_data[col].append(float(row[i]))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "corr = {}\n",
    "best_value = -1\n",
    "best_pair = (\"N/A\", \"N/A\")\n",
    "\n",
    "for c1 in columns:\n",
    "    for c2 in columns:\n",
    "        value = pearson(numeric_data[c1], numeric_data[c2])\n",
    "        corr[(c1, c2)] = value\n",
    "\n",
    "        if c1 != c2 and abs(value) > best_value:\n",
    "            best_value = abs(value)\n",
    "            best_pair = (c1, c2)\n",
    "\n",
    "\n",
    "print(\"Most correlated pair:\")\n",
    "print(f\"{best_pair[0]} and {best_pair[1]} (correlation = {best_value:.2f})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 5 (10 points)\n",
    "\n",
    "Pick three different regression model classes to try in problem 6 from the scikit-learn documentation.\n",
    "For each class, provide a link to the scikit-learn documentation, and a link to another web page describing how that kind of model works.\n",
    "The second link should not be from scikit-learn, but Wikipedia is acceptable.\n",
    "You do not need to understand the methods at this time, but it is good to be comfortable researching them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2912137359.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[159]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mLinear Regression\u001b[39m\n           ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Linear Regression \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "https://en.wikipedia.org/wiki/Linear_regression\n",
    "\n",
    "Decision Tree Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "https://en.wikipedia.org/wiki/Decision_tree_learning\n",
    "\n",
    "Random Forest Regression\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "https://en.wikipedia.org/wiki/Random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6 (50 points)\n",
    "\n",
    "Build three different regression models using the entire data set.\n",
    "Plot the actual target vs the predicted values for each in one chart.\n",
    "Compute the L2 and L1 losses for each of them.\n",
    "You may use any regression class provided provided by scikit-learn, and you may reuse one class as long as you change its parameters enough to see different results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for row in data:\n",
    "    try:\n",
    "        numbers = [float(v) for v in row]\n",
    "        y.append(numbers[0])        # body fat\n",
    "        X.append(numbers[1:])       # all other features\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "ridge_model = Ridge(alpha=10)\n",
    "forest_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": linear_model,\n",
    "    \"Ridge Regression\": ridge_model,\n",
    "    \"Random Forest\": forest_model\n",
    "}\n",
    "\n",
    "predictions = {}\n",
    "errors = {}\n",
    "\n",
    "\n",
    "for name in models:\n",
    "    model = models[name]\n",
    "\n",
    "    model.fit(X, y)\n",
    "    preds = model.predict(X)\n",
    "\n",
    "    predictions[name] = preds\n",
    "\n",
    "    l1_error = mean_absolute_error(y, preds)\n",
    "    l2_error = mean_squared_error(y, preds)\n",
    "\n",
    "    errors[name] = (l1_error, l2_error)\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for name in predictions:\n",
    "    plt.scatter(y, predictions[name], label=name, alpha=0.5)\n",
    "\n",
    "plt.plot([min(y), max(y)], [min(y), max(y)], \"k--\")\n",
    "plt.xlabel(\"Actual Body Fat\")\n",
    "plt.ylabel(\"Predicted Body Fat\")\n",
    "plt.title(\"Actual vs Predicted Body Fat\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"Model Errors:\\n\")\n",
    "\n",
    "for name in errors:\n",
    "    l1, l2 = errors[name]\n",
    "    print(name)\n",
    "    print(\"  L1 Loss (MAE):\", round(l1, 2))\n",
    "    print(\"  L2 Loss (MSE):\", round(l2, 2))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 7 (30 points)\n",
    "\n",
    "Use 5-fold cross-validation to repeat building the same three kinds of regression models. Compare the L2 losses predicted by cross-validation against the L2 losses training against the whole data set. (The difference is likely from overfitting in the latter.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_predict\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for row in data:\n",
    "    try:\n",
    "        values = [float(v) for v in row]\n",
    "        y.append(values[0])      # body fat\n",
    "        X.append(values[1:])     # all other features\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Ridge Regression\": Ridge(alpha=10),\n",
    "    \"Random Forest\": RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    )\n",
    "}\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "\n",
    "print(\"L2 Loss Comparison (MSE)\\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "\n",
    "    # Train on full dataset\n",
    "    model.fit(X, y)\n",
    "    full_preds = model.predict(X)\n",
    "    full_mse = mean_squared_error(y, full_preds)\n",
    "\n",
    "    # Cross-validation predictions\n",
    "    cv_preds = cross_val_predict(model, X, y, cv=kf)\n",
    "    cv_mse = mean_squared_error(y, cv_preds)\n",
    "\n",
    "    print(name)\n",
    "    print(\"  Training on full data MSE:\", round(full_mse, 3))\n",
    "    print(\"  5-fold CV MSE:\", round(cv_mse, 3))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 8 (25 points)\n",
    "\n",
    "Build three different regression models as in problem 6, but preprocess the data so that each column has mean zero and standard deviation one first.\n",
    "For full credit, use a scikit-learn pipeline for each model.\n",
    "For each model, compare the L2 losses -- which of them performed differently from your results in problem 6?\n",
    "\n",
    "(This process will be covered in week 13.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for row in data:\n",
    "    try:\n",
    "        nums = [float(v) for v in row]\n",
    "        y.append(nums[0])        # body fat\n",
    "        X.append(nums[1:])       # all other variables\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "linear_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])\n",
    "\n",
    "ridge_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"regressor\", Ridge(alpha=10))\n",
    "])\n",
    "\n",
    "forest_pipeline = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"regressor\", RandomForestRegressor(\n",
    "        n_estimators=100,\n",
    "        random_state=42\n",
    "    ))\n",
    "])\n",
    "\n",
    "pipelines = {\n",
    "    \"Linear Regression\": linear_pipeline,\n",
    "    \"Ridge Regression\": ridge_pipeline,\n",
    "    \"Random Forest\": forest_pipeline\n",
    "}\n",
    "\n",
    "\n",
    "print(\"L2 Loss (MSE) After Standardizing Features:\\n\")\n",
    "\n",
    "for name, pipe in pipelines.items():\n",
    "    pipe.fit(X, y)\n",
    "    predictions = pipe.predict(X)\n",
    "\n",
    "    mse = mean_squared_error(y, predictions)\n",
    "\n",
    "    print(name)\n",
    "    print(\"  L2 Loss (MSE):\", round(mse, 3))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 9 (5 points)\n",
    "\n",
    "A colleague suggests that you find better models by repeatedly building decision trees with random depth limits.\n",
    "They say that trying 1000 such models will likely find an improvement as long as you use cross validation.\n",
    "Give a one sentence response to this suggestion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for row in data:\n",
    "    try:\n",
    "        nums = [float(v) for v in row]\n",
    "        y.append(nums[0])        # body fat\n",
    "        X.append(nums[1:])       # features\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "best_mse = float(\"inf\")\n",
    "best_depth = None\n",
    "\n",
    "for i in range(1000):\n",
    "    depth = random.randint(1, 20)\n",
    "\n",
    "    tree = DecisionTreeRegressor(\n",
    "        max_depth=depth,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        tree,\n",
    "        X,\n",
    "        y,\n",
    "        cv=kf,\n",
    "        scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    mse = -scores.mean()\n",
    "\n",
    "    if mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_depth = depth\n",
    "\n",
    "print(\"Best depth found:\", best_depth)\n",
    "print(\"Best cross-validated L2 loss (MSE):\", round(best_mse, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 10 (10 points)\n",
    "\n",
    "Pick a best model from all the models that you built and otherwise described in this project.\n",
    "Explain how you picked it, including what criteria you chose, and how the other models compared by that criteria.\n",
    "As much as possible, justify that problem in the context of the original data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Step 1: Prepare X and y\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for row in data:\n",
    "    try:\n",
    "        values = []\n",
    "        for v in row:\n",
    "            values.append(float(v))\n",
    "\n",
    "        y.append(values[0])        # body fat is the target\n",
    "        X.append(values[1:])       # everything else is a feature\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "# Step 2: Create the models\n",
    "\n",
    "\n",
    "linear_model = LinearRegression()\n",
    "ridge_model = Ridge(alpha=10)\n",
    "forest_model = RandomForestRegressor(\n",
    "    n_estimators=100,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "models = {\n",
    "    \"Linear Regression\": linear_model,\n",
    "    \"Ridge Regression\": ridge_model,\n",
    "    \"Random Forest\": forest_model\n",
    "}\n",
    "\n",
    "\n",
    "# Step 3: Set up 5-fold cross-validation\n",
    "\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Step 4: Evaluate models\n",
    "\n",
    "model_errors = {}\n",
    "\n",
    "for model_name in models:\n",
    "    model = models[model_name]\n",
    "\n",
    "    scores = cross_val_score(\n",
    "        model,\n",
    "        X,\n",
    "        y,\n",
    "        cv=kf,\n",
    "        scoring=\"neg_mean_squared_error\"\n",
    "    )\n",
    "\n",
    "    mse = -scores.mean()\n",
    "    model_errors[model_name] = mse\n",
    "\n",
    "# Step 5: Print results and pick best\n",
    "\n",
    "\n",
    "print(\"Cross-validated L2 loss (MSE):\\n\")\n",
    "\n",
    "best_model = None\n",
    "best_mse = None\n",
    "\n",
    "for name in model_errors:\n",
    "    mse = model_errors[name]\n",
    "    print(name, \"MSE:\", round(mse, 3))\n",
    "\n",
    "    if best_mse is None or mse < best_mse:\n",
    "        best_mse = mse\n",
    "        best_model = name\n",
    "\n",
    "print(\"\\nBest model overall:\")\n",
    "print(best_model, \"with MSE =\", round(best_mse, 3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YOUR ANSWERS HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
